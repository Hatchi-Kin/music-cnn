{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tempfile\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import librosa\n",
    "import torch\n",
    "import mlflow.pytorch\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "DEFAULT_SETTINGS = {\n",
    "    \"minio_endpoint\": os.getenv(\"REMOTE_MLFLOW_STORAGE_URI\"),\n",
    "    \"minio_music_net_bucket_name\": os.getenv(\"REMOTE_MLFLOW_BUCKET_NAME\"),\n",
    "    \"minio_access_key\": os.getenv(\"AWS_ACCESS_KEY_ID\"),\n",
    "    \"minio_secret_key\": os.getenv(\"AWS_SECRET_ACCESS_KEY\"),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "MAPPING_DICT_MUSIC_NET = {\n",
    "    'blues': 0, 'chanson': 1, 'classical': 2, 'country': 3, 'dance': 4, 'dub': 5,\n",
    "    'electro': 6, 'folk': 7, 'funk': 8, 'hard rock': 9, 'hip-hop': 10, 'house': 11,\n",
    "    'jazz': 12, 'metal': 13, 'pop': 14, 'rap': 15, 'reggae': 16, 'rock': 17,\n",
    "}\n",
    "\n",
    "\n",
    "def create_preprocessed_spectrogram(audio_path, sr=22050, n_mels=128, fmax=8000, img_size=(224, 224), start_time=20, segment_duration=20):\n",
    "    try:\n",
    "        # Load the audio file\n",
    "        y, sr = librosa.load(audio_path, sr=sr, offset=start_time, duration=segment_duration)\n",
    "        \n",
    "        # Generate the spectrogram\n",
    "        S = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=n_mels, fmax=fmax)\n",
    "        S_DB = librosa.power_to_db(S, ref=np.max)\n",
    "        \n",
    "        # Plot the spectrogram\n",
    "        plt.figure(figsize=(10, 4))\n",
    "        plt.axis('off')\n",
    "        librosa.display.specshow(S_DB, sr=sr, x_axis=None, y_axis=None, fmax=fmax)\n",
    "        \n",
    "        # Save the plot to a temporary file\n",
    "        with tempfile.NamedTemporaryFile(suffix='.png', delete=False) as tmpfile:\n",
    "            plt.savefig(tmpfile.name, bbox_inches='tight', pad_inches=0)\n",
    "            plt.close()\n",
    "            \n",
    "            # Open the image and resize it\n",
    "            img = Image.open(tmpfile.name).convert('RGB')  # Convert to RGB\n",
    "            img = img.resize(img_size, Image.Resampling.LANCZOS)\n",
    "            os.remove(tmpfile.name)\n",
    "        \n",
    "        # Transform the image to tensor\n",
    "        transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "        ])\n",
    "        img_tensor = transform(img).unsqueeze(0)  # Add batch dimension\n",
    "        \n",
    "        return img_tensor\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {audio_path}: {e}\")\n",
    "        return None\n",
    "    \n",
    "\n",
    "def get_production_model():\n",
    "    # Load the model using mlflow\n",
    "    minio_url = f\"s3://{DEFAULT_SETTINGS['minio_music_net_bucket_name']}/data/\"\n",
    "\n",
    "    os.environ[\"AWS_ACCESS_KEY_ID\"] = DEFAULT_SETTINGS['minio_access_key']\n",
    "    os.environ[\"AWS_SECRET_ACCESS_KEY\"] = DEFAULT_SETTINGS['minio_secret_key']\n",
    "    os.environ[\"MLFLOW_S3_ENDPOINT_URL\"] = f\"https://{DEFAULT_SETTINGS['minio_endpoint']}\"\n",
    "\n",
    "    map_location = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    return mlflow.pytorch.load_model(minio_url, map_location=map_location)\n",
    "\n",
    "\n",
    "def predicted_item_to_class_name(predicted_item):\n",
    "    class_names = ['class1', 'class2', 'class3', 'class4', 'class5']\n",
    "    return class_names[predicted_item]\n",
    "\n",
    "\n",
    "def predict_with_production_music_net(model, img_tensor):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    img_tensor = img_tensor.to(device)\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        output = model(img_tensor)\n",
    "        _, predicted = torch.max(output, 1)\n",
    "    \n",
    "    idx_to_class = {v: k for k, v in MAPPING_DICT_MUSIC_NET.items()}\n",
    "    predicted_class_name = idx_to_class[predicted.item()]\n",
    "\n",
    "    return predicted_class_name\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_genre(audio_path: str):\n",
    "    \"\"\"\n",
    "    Predicts the genre of a music segment using a pre-trained MusicNet model.\n",
    "\n",
    "    - **audio_path**: str - The path to the audio file.\n",
    "    - **start_time**: int - The start time of the segment.\n",
    "    - **segment_duration**: int - The duration of the segment.\n",
    "    - **return**: dict - A dictionary containing the predicted genre and the corresponding probability.\n",
    "    \"\"\"\n",
    "    genre = None  # Initialize the genre variable\n",
    "\n",
    "    try:\n",
    "        # Load the production model\n",
    "        model = get_production_model()\n",
    "        if model is None:\n",
    "            print(\"Failed to load the production model.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading the production model: {e}\")\n",
    "\n",
    "    try:\n",
    "        # Create a preprocessed spectrogram\n",
    "        img_tensor = create_preprocessed_spectrogram(audio_path)\n",
    "        if img_tensor is None:\n",
    "            print(\"Failed to create the preprocessed spectrogram.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating the preprocessed spectrogram: {e}\")\n",
    "\n",
    "    try:\n",
    "        # Predict the genre\n",
    "        genre = predict_with_production_music_net(model, img_tensor)\n",
    "    except Exception as e:\n",
    "        print(f\"Error predicting the genre: {e}\")\n",
    "\n",
    "    return {\"genre\": genre}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading artifacts: 100%|██████████| 10/10 [00:00<00:00, 241.73it/s] \n",
      "2024/11/04 12:47:34 WARNING mlflow.pytorch: Stored model version '2.4.1+cu121' does not match installed PyTorch version '2.5.1+cu124'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'genre': 'dub'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_path = \"/home/kin/Documents/music_similarity/preprocessing/MegaSet/Parov Stelar/Parov Stelar - That Swing (2009)/14. A Night In Torino.mp3\"\n",
    "predict_genre(audio_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create a new user and set it as admin, then delete the default admin user\n",
    "\n",
    "# import os\n",
    "# import time\n",
    "# import logging\n",
    "\n",
    "# import mlflow\n",
    "# from mlflow.server.auth.client import AuthServiceClient\n",
    "\n",
    "# logging.basicConfig(level=logging.INFO)\n",
    "# logger = logging.getLogger(__name__)\n",
    "\n",
    "# # Wait for the MLflow server to start\n",
    "# time.sleep(20)\n",
    "\n",
    "# MLFLOW_TRACKIN_FULL_URL = os.getenv(\"MLFLOW_TRACKIN_FULL_URL\")\n",
    "# NEW_USER_USERNAME = os.getenv(\"NEW_USER_USERNAME\")\n",
    "# NEW_USER_PASSWORD = os.getenv(\"NEW_USER_PASSWORD\")\n",
    "\n",
    "# # Set the tracking URI\n",
    "# mlflow.set_tracking_uri(MLFLOW_TRACKIN_FULL_URL)\n",
    "\n",
    "# # Set environment variables for authentication\n",
    "# os.environ['MLFLOW_TRACKING_USERNAME'] = \"admin\"\n",
    "# os.environ['MLFLOW_TRACKING_PASSWORD'] = \"password\"\n",
    "\n",
    "# # Initialize the AuthServiceClient with admin credentials\n",
    "# client = AuthServiceClient(MLFLOW_TRACKIN_FULL_URL)\n",
    "\n",
    "# # Create a new user\n",
    "# try:\n",
    "#     client.create_user(NEW_USER_USERNAME, NEW_USER_PASSWORD)\n",
    "#     logger.info(\"User created successfully.\")\n",
    "# except Exception as e:\n",
    "#     logger.error(f\"Failed to create user: {e}\")\n",
    "\n",
    "# # Set the new user as admin\n",
    "# try:\n",
    "#     client.update_user_admin(NEW_USER_USERNAME, True)\n",
    "#     logger.info(\"User set as admin successfully.\")\n",
    "# except Exception as e:\n",
    "#     logger.error(f\"Failed to set user as admin: {e}\")\n",
    "\n",
    "# # Delete the default admin user\n",
    "# try:\n",
    "#     client.delete_user(\"admin\")\n",
    "#     logger.info(\"Default admin user deleted successfully.\")\n",
    "# except Exception as e:\n",
    "#     logger.error(f\"Failed to delete default admin user: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
