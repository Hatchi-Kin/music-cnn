{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from minio import Minio\n",
    "from minio.error import S3Error\n",
    "\n",
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient\n",
    "import mlflow.pytorch\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# Set up MLflow tracking URI and MinIO configuration\n",
    "MLFLOW_TRACKING_URI = os.getenv('MLFLOW_REMOTE_SERVER_URI')\n",
    "MLFLOW_S3_ENDPOINT_URL = f\"https://{os.getenv('REMOTE_MLFLOW_STORAGE_URI')}\"\n",
    "AWS_ACCESS_KEY_ID = os.getenv('NEW_USER_USERNAME')\n",
    "AWS_SECRET_ACCESS_KEY = os.getenv('NEW_USER_PASSWORD')\n",
    "REMOTE_MLFLOW_STORAGE_URI = os.getenv('REMOTE_MLFLOW_STORAGE_URI')\n",
    "\n",
    "os.environ['MLFLOW_TRACKING_URI'] = MLFLOW_TRACKING_URI\n",
    "os.environ['MLFLOW_S3_ENDPOINT_URL'] = MLFLOW_S3_ENDPOINT_URL\n",
    "os.environ['AWS_ACCESS_KEY_ID'] = AWS_ACCESS_KEY_ID\n",
    "os.environ['AWS_SECRET_ACCESS_KEY'] = AWS_SECRET_ACCESS_KEY\n",
    "os.environ['MLFLOW_S3_IGNORE_TLS'] = 'false'\n",
    "\n",
    "mlflow_client = MlflowClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21228c06f6b643938b156510312de1a5/artifacts/classification_report.txt\n",
      "21228c06f6b643938b156510312de1a5/artifacts/model/MLmodel\n",
      "21228c06f6b643938b156510312de1a5/artifacts/model/conda.yaml\n",
      "21228c06f6b643938b156510312de1a5/artifacts/model/data/model.pth\n",
      "21228c06f6b643938b156510312de1a5/artifacts/model/data/pickle_module_info.txt\n",
      "21228c06f6b643938b156510312de1a5/artifacts/model/python_env.yaml\n",
      "21228c06f6b643938b156510312de1a5/artifacts/model/requirements.txt\n",
      "57cedbcc86d3444fa3c079443bfeec7c/artifacts/classification_report.txt\n",
      "57cedbcc86d3444fa3c079443bfeec7c/artifacts/model/MLmodel\n",
      "57cedbcc86d3444fa3c079443bfeec7c/artifacts/model/conda.yaml\n",
      "57cedbcc86d3444fa3c079443bfeec7c/artifacts/model/data/model.pth\n",
      "57cedbcc86d3444fa3c079443bfeec7c/artifacts/model/data/pickle_module_info.txt\n",
      "57cedbcc86d3444fa3c079443bfeec7c/artifacts/model/python_env.yaml\n",
      "57cedbcc86d3444fa3c079443bfeec7c/artifacts/model/requirements.txt\n",
      "6fed7bbe04d14e9aa4ffbce4b48a56e8/artifacts/model/MLmodel\n",
      "6fed7bbe04d14e9aa4ffbce4b48a56e8/artifacts/model/conda.yaml\n",
      "6fed7bbe04d14e9aa4ffbce4b48a56e8/artifacts/model/data/model.pth\n",
      "6fed7bbe04d14e9aa4ffbce4b48a56e8/artifacts/model/data/pickle_module_info.txt\n",
      "6fed7bbe04d14e9aa4ffbce4b48a56e8/artifacts/model/python_env.yaml\n",
      "6fed7bbe04d14e9aa4ffbce4b48a56e8/artifacts/model/requirements.txt\n",
      "Music_Genre_Classification_V4_20:04:39.9682/d38eb340c51e4c4b8b3b50a60bbfa158/artifacts/model/MLmodel\n",
      "Music_Genre_Classification_V4_20:04:39.9682/d38eb340c51e4c4b8b3b50a60bbfa158/artifacts/model/conda.yaml\n",
      "Music_Genre_Classification_V4_20:04:39.9682/d38eb340c51e4c4b8b3b50a60bbfa158/artifacts/model/data/model.pth\n",
      "Music_Genre_Classification_V4_20:04:39.9682/d38eb340c51e4c4b8b3b50a60bbfa158/artifacts/model/data/pickle_module_info.txt\n",
      "Music_Genre_Classification_V4_20:04:39.9682/d38eb340c51e4c4b8b3b50a60bbfa158/artifacts/model/python_env.yaml\n",
      "Music_Genre_Classification_V4_20:04:39.9682/d38eb340c51e4c4b8b3b50a60bbfa158/artifacts/model/requirements.txt\n",
      "f9c8f61982414ccdbd22da5e7463ea70/artifacts/classification_report.txt\n",
      "f9c8f61982414ccdbd22da5e7463ea70/artifacts/model/MLmodel\n",
      "f9c8f61982414ccdbd22da5e7463ea70/artifacts/model/conda.yaml\n",
      "f9c8f61982414ccdbd22da5e7463ea70/artifacts/model/data/model.pth\n",
      "f9c8f61982414ccdbd22da5e7463ea70/artifacts/model/data/pickle_module_info.txt\n",
      "f9c8f61982414ccdbd22da5e7463ea70/artifacts/model/python_env.yaml\n",
      "f9c8f61982414ccdbd22da5e7463ea70/artifacts/model/requirements.txt\n",
      "mlflow/40/4ca1f0f2b8fa463a9e93b7db495262f7/artifacts/model/requirements.txt\n",
      "mlflow/40/6d69451b7f9d4a4fae8a796cb692839e/artifacts/model/MLmodel\n",
      "mlflow/40/6d69451b7f9d4a4fae8a796cb692839e/artifacts/model/conda.yaml\n",
      "mlflow/40/6d69451b7f9d4a4fae8a796cb692839e/artifacts/model/model.pkl\n",
      "mlflow/40/6d69451b7f9d4a4fae8a796cb692839e/artifacts/model/python_env.yaml\n",
      "mlflow/40/6d69451b7f9d4a4fae8a796cb692839e/artifacts/model/requirements.txt\n",
      "test_file.txt\n"
     ]
    }
   ],
   "source": [
    "# Set up MinIO client\n",
    "minio_client = Minio(\n",
    "    endpoint=REMOTE_MLFLOW_STORAGE_URI,\n",
    "    access_key=AWS_ACCESS_KEY_ID,\n",
    "    secret_key=AWS_SECRET_ACCESS_KEY,\n",
    "    secure=True\n",
    ")\n",
    "\n",
    "# List objects in the bucket\n",
    "bucket_name = \"mlflowbucket\"\n",
    "# prefix = \"mlflow/\"\n",
    "prefix = \"\"\n",
    "try:\n",
    "    objects = minio_client.list_objects(bucket_name, prefix=prefix, recursive=True)\n",
    "    for obj in objects:\n",
    "        print(obj.object_name)\n",
    "except S3Error as e:\n",
    "    print(\"Error occurred:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment ID: 46, Name: Music_Genre_Classification_V2_19:17:29.8986\n",
      "Experiment ID: 45, Name: Music_Genre_Classification_V2_18:52:06.3148\n",
      "Experiment ID: 44, Name: Music_Genre_Classification_V2_18:35:37.0929\n",
      "Experiment ID: 43, Name: Music_Genre_Classification_V2_17:49:20.0907\n",
      "Experiment ID: 42, Name: Music_Genre_Classification_V2_19:35:42.6849\n",
      "Experiment ID: 41, Name: Music_Genre_Classification_V4_20:04:39.9682\n",
      "Experiment ID: 37, Name: Music_Genre_Classification_V2_11:56:15.3037\n",
      "Experiment ID: 25, Name: Music_Genre_Classification_V2_19:11:34.5089\n",
      "Experiment ID: 17, Name: Music Genre Classification 22:43:35.8824\n"
     ]
    }
   ],
   "source": [
    "# List experiments\n",
    "experiments = mlflow.search_experiments()\n",
    "\n",
    "for experiment in experiments:\n",
    "    print(f\"Experiment ID: {experiment.experiment_id}, Name: {experiment.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "artifact_uri for experiment_id 41: s3://mlflowbucket/Music_Genre_Classification_V4_20:04:39.9682/d38eb340c51e4c4b8b3b50a60bbfa158/artifacts\n"
     ]
    }
   ],
   "source": [
    "# List runs for a specific experiment\n",
    "experiment_id = \"41\"\n",
    "runs = mlflow.search_runs(experiment_ids=[experiment_id])\n",
    "artifact_uri = runs.iloc[0].artifact_uri\n",
    "print(f\"artifact_uri for experiment_id {experiment_id}: {artifact_uri}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Music_Genre_Classification_V4_20:04:39.9682/d38eb340c51e4c4b8b3b50a60bbfa158/artifacts'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_s3_path(artifact_uri):\n",
    "    if artifact_uri.startswith('s3://'):\n",
    "        return '/'.join(artifact_uri.split('/')[3:])\n",
    "    else:\n",
    "        raise ValueError(\"The provided URI does not start with 's3://'\")\n",
    "\n",
    "s3_path_to_model = extract_s3_path(artifact_uri)\n",
    "s3_path_to_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_objects_from_minio(minio_client, bucket_name, s3_path_to_model, local_file_path):\n",
    "    objects = minio_client.list_objects(bucket_name, prefix=s3_path_to_model, recursive=True)\n",
    "    for obj in objects:\n",
    "        local_file = os.path.join(local_file_path, os.path.relpath(obj.object_name, s3_path_to_model))\n",
    "        os.makedirs(os.path.dirname(local_file), exist_ok=True)\n",
    "        minio_client.fget_object(bucket_name, obj.object_name, local_file)\n",
    "\n",
    "# local_file_path = f\"models/{experiment_id}\"\n",
    "\n",
    "# download_objects_from_minio(\n",
    "#     minio_client, \n",
    "#     bucket_name, \n",
    "#     s3_path_to_model, \n",
    "#     local_file_path\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_model_in_production_bucket(minio_client, bucket_name, model_folder_path):\n",
    "    try:\n",
    "        # Delete the existing model\n",
    "        objects = minio_client.list_objects(bucket_name, prefix='data/', recursive=True)\n",
    "        for obj in objects:\n",
    "            minio_client.remove_object(bucket_name, obj.object_name)\n",
    "    except Exception as e:\n",
    "        return f\"Error deleting existing model: {e}\"\n",
    "\n",
    "    # upload the new model's folder and all its contents\n",
    "    if [obj for obj in minio_client.list_objects(bucket_name, recursive=True)] == []:\n",
    "        try:\n",
    "            # Upload the new model's folder and all its contents\n",
    "            for root, dirs, files in os.walk(model_folder_path):\n",
    "                for file in files:\n",
    "                    local_file_path = os.path.join(root, file)\n",
    "                    relative_path = os.path.relpath(local_file_path, model_folder_path)\n",
    "                    minio_client.fput_object(bucket_name, f\"data/{relative_path}\", local_file_path)\n",
    "        except Exception as e:\n",
    "            return f\"Error uploading new model: {e}\"\n",
    "    \n",
    "    return \"Model updated successfully\"\n",
    "\n",
    "\n",
    "bucket_name = \"music-net-prod\"\n",
    "# update_model_in_production_bucket(minio_client, bucket_name, local_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/model/MLmodel\n",
      "data/model/conda.yaml\n",
      "data/model/data/model.pth\n",
      "data/model/data/pickle_module_info.txt\n",
      "data/model/python_env.yaml\n",
      "data/model/requirements.txt\n"
     ]
    }
   ],
   "source": [
    "objects = minio_client.list_objects(bucket_name, recursive=True)\n",
    "\n",
    "for obj in objects:\n",
    "    print(obj.object_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_production_model():\n",
    "    # load the model using mlflow\n",
    "    minio_url = f\"s3://{bucket_name}/data/model/\"\n",
    "    print(f\"Minio URL: {minio_url}\")\n",
    "\n",
    "    os.environ[\"AWS_ACCESS_KEY_ID\"] = AWS_ACCESS_KEY_ID\n",
    "    os.environ[\"AWS_SECRET_ACCESS_KEY\"] = AWS_SECRET_ACCESS_KEY\n",
    "    os.environ[\"MLFLOW_S3_ENDPOINT_URL\"] = MLFLOW_S3_ENDPOINT_URL\n",
    "\n",
    "    # Check if CUDA is available\n",
    "    if torch.cuda.is_available():\n",
    "        return mlflow.pytorch.load_model(minio_url)\n",
    "    else:\n",
    "        return mlflow.pytorch.load_model(minio_url, map_location=torch.device('cpu'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minio URL: s3://music-net-prod/data/model/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "219a0e3f04764badbf0448f973509e14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/21 22:24:13 WARNING mlflow.pytorch: Stored model version '2.5.0+cu121' does not match installed PyTorch version '2.6.0.dev20241104+cu124'\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    model = get_production_model()\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MusicNet(\n",
       "  (conv1): Conv2d(3, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv3): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv4): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (batchnorm1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (batchnorm2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (batchnorm3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (batchnorm4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       "  (fc1): Linear(in_features=12544, out_features=18, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "test_dir = \"/home/kin/Documents/music-cnn/beat_openl3/DATASET/CNNSET/test\"\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize to the desired size\n",
    "    transforms.ToTensor(),  # Convert to tensor\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])  # Normalize (adjust mean and std as needed)\n",
    "])\n",
    "\n",
    "test_dataset = datasets.ImageFolder(root=test_dir, transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=25, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, classification_report\n",
    "import pandas as pd\n",
    "\n",
    "def test_model(model, test_loader, device):\n",
    "    model.eval()\n",
    "    y_true, y_pred = [], []\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            _, predicted = torch.max(output, 1)\n",
    "            y_true.extend(target.cpu().numpy())\n",
    "            y_pred.extend(predicted.cpu().numpy())\n",
    "\n",
    "    # Calculate metrics\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "    recall = recall_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "    class_report_dict = classification_report(y_true, y_pred, zero_division=0, output_dict=True)\n",
    "    class_report_df = pd.DataFrame(class_report_dict).transpose()\n",
    "\n",
    "\n",
    "    # print(f\"Confusion Matrix:\\n{cm}\")\n",
    "    # print(f\"Precision: {precision:.4f}\")\n",
    "    # print(f\"Recall: {recall:.4f}\")\n",
    "    # print(f\"F1 Score: {f1:.4f}\")\n",
    "    # print(f\"Classification Report:\\n{class_report}\")\n",
    "\n",
    "    return cm, precision, recall, f1, class_report_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.444444</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.608686</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.562066</td>\n",
       "      <td>72.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.608686</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.562066</td>\n",
       "      <td>72.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score    support\n",
       "0              0.666667  0.500000  0.571429   4.000000\n",
       "1              0.500000  0.250000  0.333333   4.000000\n",
       "2              0.666667  0.500000  0.571429   4.000000\n",
       "3              1.000000  0.500000  0.666667   4.000000\n",
       "4              0.800000  1.000000  0.888889   4.000000\n",
       "5              0.800000  1.000000  0.888889   4.000000\n",
       "6              0.000000  0.000000  0.000000   4.000000\n",
       "7              0.500000  0.500000  0.500000   4.000000\n",
       "8              1.000000  0.750000  0.857143   4.000000\n",
       "9              0.444444  1.000000  0.615385   4.000000\n",
       "10             0.428571  0.750000  0.545455   4.000000\n",
       "11             1.000000  0.500000  0.666667   4.000000\n",
       "12             0.600000  0.750000  0.666667   4.000000\n",
       "13             0.750000  0.750000  0.750000   4.000000\n",
       "14             0.500000  0.500000  0.500000   4.000000\n",
       "15             0.000000  0.000000  0.000000   4.000000\n",
       "16             1.000000  0.500000  0.666667   4.000000\n",
       "17             0.300000  0.750000  0.428571   4.000000\n",
       "accuracy       0.583333  0.583333  0.583333   0.583333\n",
       "macro avg      0.608686  0.583333  0.562066  72.000000\n",
       "weighted avg   0.608686  0.583333  0.562066  72.000000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm, precision, recall, f1, class_report_df = test_model(model, test_loader, torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n",
    "\n",
    "class_report_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here's how to interpret the classification report:\n",
    "\n",
    "# Precision: The ratio of correctly predicted positive observations to the total predicted positives. High precision indicates a low false positive rate.\n",
    "# Recall: The ratio of correctly predicted positive observations to all observations in the actual class. High recall indicates a low false negative rate.\n",
    "# F1-Score: The weighted average of precision and recall. It considers both false positives and false negatives. A high F1-score indicates a good balance between precision and recall.\n",
    "# Support: The number of actual occurrences of the class in the dataset.\n",
    "# For each class (0 to 17):\n",
    "\n",
    "# Precision: How many selected items are relevant.\n",
    "# Recall: How many relevant items are selected.\n",
    "# F1-Score: The harmonic mean of precision and recall.\n",
    "# Support: The number of true instances for each class.\n",
    "# Overall metrics:\n",
    "\n",
    "# Accuracy: The ratio of correctly predicted instances to the total instances.\n",
    "# Macro avg: The average of the precision, recall, and F1-score for all classes, treating all classes equally.\n",
    "# Weighted avg: The average of the precision, recall, and F1-score for all classes, weighted by the number of true instances for each class.\n",
    "# Example Interpretation:\n",
    "# Class 0:\n",
    "\n",
    "# Precision: 0.67 (67% of the predicted class 0 instances are correct)\n",
    "# Recall: 0.50 (50% of the actual class 0 instances are correctly predicted)\n",
    "# F1-Score: 0.57 (balance between precision and recall)\n",
    "# Support: 4 (there are 4 actual instances of class 0)\n",
    "# Overall Accuracy: 0.5833 (58.33% of the total instances are correctly predicted)\n",
    "\n",
    "# Macro avg:\n",
    "\n",
    "# Precision: 0.6087\n",
    "# Recall: 0.5833\n",
    "# F1-Score: 0.5621\n",
    "# Weighted avg:\n",
    "\n",
    "# Precision: 0.6087\n",
    "# Recall: 0.5833\n",
    "# F1-Score: 0.5621\n",
    "# These metrics help you understand the performance of your model across different classes and overall."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
