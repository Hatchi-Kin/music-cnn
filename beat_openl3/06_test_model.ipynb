{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from minio import Minio\n",
    "from minio.error import S3Error\n",
    "\n",
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient\n",
    "import mlflow.pytorch\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# Set up MLflow tracking URI and MinIO configuration\n",
    "MLFLOW_TRACKING_URI = os.getenv('MLFLOW_REMOTE_SERVER_URI')\n",
    "MLFLOW_S3_ENDPOINT_URL = f'https://{os.getenv('REMOTE_MLFLOW_STORAGE_URI')}'\n",
    "AWS_ACCESS_KEY_ID = os.getenv('NEW_USER_USERNAME')\n",
    "AWS_SECRET_ACCESS_KEY = os.getenv('NEW_USER_PASSWORD')\n",
    "REMOTE_MLFLOW_STORAGE_URI = os.getenv('REMOTE_MLFLOW_STORAGE_URI')\n",
    "\n",
    "os.environ['MLFLOW_TRACKING_URI'] = MLFLOW_TRACKING_URI\n",
    "os.environ['MLFLOW_S3_ENDPOINT_URL'] = MLFLOW_S3_ENDPOINT_URL\n",
    "os.environ['AWS_ACCESS_KEY_ID'] = AWS_ACCESS_KEY_ID\n",
    "os.environ['AWS_SECRET_ACCESS_KEY'] = AWS_SECRET_ACCESS_KEY\n",
    "os.environ['MLFLOW_S3_IGNORE_TLS'] = 'false'\n",
    "\n",
    "mlflow_client = MlflowClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Music_Genre_Classification_V4_20:04:39.9682/d38eb340c51e4c4b8b3b50a60bbfa158/artifacts/model/MLmodel\n",
      "Music_Genre_Classification_V4_20:04:39.9682/d38eb340c51e4c4b8b3b50a60bbfa158/artifacts/model/conda.yaml\n",
      "Music_Genre_Classification_V4_20:04:39.9682/d38eb340c51e4c4b8b3b50a60bbfa158/artifacts/model/data/model.pth\n",
      "Music_Genre_Classification_V4_20:04:39.9682/d38eb340c51e4c4b8b3b50a60bbfa158/artifacts/model/data/pickle_module_info.txt\n",
      "Music_Genre_Classification_V4_20:04:39.9682/d38eb340c51e4c4b8b3b50a60bbfa158/artifacts/model/python_env.yaml\n",
      "Music_Genre_Classification_V4_20:04:39.9682/d38eb340c51e4c4b8b3b50a60bbfa158/artifacts/model/requirements.txt\n",
      "mlflow/40/4ca1f0f2b8fa463a9e93b7db495262f7/artifacts/model/requirements.txt\n",
      "mlflow/40/6d69451b7f9d4a4fae8a796cb692839e/artifacts/model/MLmodel\n",
      "mlflow/40/6d69451b7f9d4a4fae8a796cb692839e/artifacts/model/conda.yaml\n",
      "mlflow/40/6d69451b7f9d4a4fae8a796cb692839e/artifacts/model/model.pkl\n",
      "mlflow/40/6d69451b7f9d4a4fae8a796cb692839e/artifacts/model/python_env.yaml\n",
      "mlflow/40/6d69451b7f9d4a4fae8a796cb692839e/artifacts/model/requirements.txt\n",
      "test_file.txt\n"
     ]
    }
   ],
   "source": [
    "# Set up MinIO client\n",
    "minio_client = Minio(\n",
    "    endpoint=REMOTE_MLFLOW_STORAGE_URI,\n",
    "    access_key=AWS_ACCESS_KEY_ID,\n",
    "    secret_key=AWS_SECRET_ACCESS_KEY,\n",
    "    secure=True\n",
    ")\n",
    "\n",
    "# List objects in the bucket\n",
    "bucket_name = \"mlflowbucket\"\n",
    "# prefix = \"mlflow/\"\n",
    "prefix = \"\"\n",
    "try:\n",
    "    objects = minio_client.list_objects(bucket_name, prefix=prefix, recursive=True)\n",
    "    for obj in objects:\n",
    "        print(obj.object_name)\n",
    "except S3Error as e:\n",
    "    print(\"Error occurred:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment ID: 41, Name: Music_Genre_Classification_V4_20:04:39.9682\n",
      "Experiment ID: 37, Name: Music_Genre_Classification_V2_11:56:15.3037\n",
      "Experiment ID: 25, Name: Music_Genre_Classification_V2_19:11:34.5089\n",
      "Experiment ID: 17, Name: Music Genre Classification 22:43:35.8824\n"
     ]
    }
   ],
   "source": [
    "# List experiments\n",
    "experiments = mlflow.search_experiments()\n",
    "\n",
    "for experiment in experiments:\n",
    "    print(f\"Experiment ID: {experiment.experiment_id}, Name: {experiment.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "artifact_uri for experiment_id 41: s3://mlflowbucket/Music_Genre_Classification_V4_20:04:39.9682/d38eb340c51e4c4b8b3b50a60bbfa158/artifacts\n"
     ]
    }
   ],
   "source": [
    "# List runs for a specific experiment\n",
    "experiment_id = \"41\"\n",
    "runs = mlflow.search_runs(experiment_ids=[experiment_id])\n",
    "artifact_uri = runs.iloc[0].artifact_uri\n",
    "print(f\"artifact_uri for experiment_id {experiment_id}: {artifact_uri}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Music_Genre_Classification_V4_20:04:39.9682/d38eb340c51e4c4b8b3b50a60bbfa158/artifacts'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_s3_path(artifact_uri):\n",
    "    if artifact_uri.startswith('s3://'):\n",
    "        return '/'.join(artifact_uri.split('/')[3:])\n",
    "    else:\n",
    "        raise ValueError(\"The provided URI does not start with 's3://'\")\n",
    "\n",
    "s3_path_to_model = extract_s3_path(artifact_uri)\n",
    "s3_path_to_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_objects_from_minio(minio_client, bucket_name, s3_path_to_model, local_file_path):\n",
    "    objects = minio_client.list_objects(bucket_name, prefix=s3_path_to_model, recursive=True)\n",
    "    for obj in objects:\n",
    "        local_file = os.path.join(local_file_path, os.path.relpath(obj.object_name, s3_path_to_model))\n",
    "        os.makedirs(os.path.dirname(local_file), exist_ok=True)\n",
    "        minio_client.fget_object(bucket_name, obj.object_name, local_file)\n",
    "\n",
    "# local_file_path = f\"models/{experiment_id}\"\n",
    "\n",
    "# download_objects_from_minio(\n",
    "#     minio_client, \n",
    "#     bucket_name, \n",
    "#     s3_path_to_model, \n",
    "#     local_file_path\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_model_in_production_bucket(minio_client, bucket_name, model_folder_path):\n",
    "    try:\n",
    "        # Delete the existing model\n",
    "        objects = minio_client.list_objects(bucket_name, prefix='data/', recursive=True)\n",
    "        for obj in objects:\n",
    "            minio_client.remove_object(bucket_name, obj.object_name)\n",
    "    except Exception as e:\n",
    "        return f\"Error deleting existing model: {e}\"\n",
    "\n",
    "    # upload the new model's folder and all its contents\n",
    "    if [obj for obj in minio_client.list_objects(bucket_name, recursive=True)] == []:\n",
    "        try:\n",
    "            # Upload the new model's folder and all its contents\n",
    "            for root, dirs, files in os.walk(model_folder_path):\n",
    "                for file in files:\n",
    "                    local_file_path = os.path.join(root, file)\n",
    "                    relative_path = os.path.relpath(local_file_path, model_folder_path)\n",
    "                    minio_client.fput_object(bucket_name, f\"data/{relative_path}\", local_file_path)\n",
    "        except Exception as e:\n",
    "            return f\"Error uploading new model: {e}\"\n",
    "    \n",
    "    return \"Model updated successfully\"\n",
    "\n",
    "\n",
    "bucket_name = \"music-net-prod\"\n",
    "# update_model_in_production_bucket(minio_client, bucket_name, local_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/model/MLmodel\n",
      "data/model/conda.yaml\n",
      "data/model/data/model.pth\n",
      "data/model/data/pickle_module_info.txt\n",
      "data/model/python_env.yaml\n",
      "data/model/requirements.txt\n"
     ]
    }
   ],
   "source": [
    "objects = minio_client.list_objects(bucket_name, recursive=True)\n",
    "\n",
    "for obj in objects:\n",
    "    print(obj.object_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_production_model():\n",
    "    # load the model using mlflow\n",
    "    minio_url = f\"s3://{bucket_name}/data/model/\"\n",
    "    print(f\"Minio URL: {minio_url}\")\n",
    "\n",
    "    os.environ[\"AWS_ACCESS_KEY_ID\"] = AWS_ACCESS_KEY_ID\n",
    "    os.environ[\"AWS_SECRET_ACCESS_KEY\"] = AWS_SECRET_ACCESS_KEY\n",
    "    os.environ[\"MLFLOW_S3_ENDPOINT_URL\"] = MLFLOW_S3_ENDPOINT_URL\n",
    "\n",
    "    # Check if CUDA is available\n",
    "    if torch.cuda.is_available():\n",
    "        return mlflow.pytorch.load_model(minio_url)\n",
    "    else:\n",
    "        return mlflow.pytorch.load_model(minio_url, map_location=torch.device('cpu'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minio URL: s3://music-net-prod/data/model/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kin/Documents/music-cnn/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Downloading artifacts: 100%|██████████| 6/6 [00:00<00:00, 70.94it/s]   \n",
      "2024/11/11 20:00:45 WARNING mlflow.pytorch: Stored model version '2.5.0+cu121' does not match installed PyTorch version '2.6.0.dev20241104+cu124'\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    model = get_production_model()\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MusicNet(\n",
       "  (conv1): Conv2d(3, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv3): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv4): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (batchnorm1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (batchnorm2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (batchnorm3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (batchnorm4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       "  (fc1): Linear(in_features=12544, out_features=18, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "test_dir = \"beat_openl3/DATASET/CNNSET/test\"\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize to the desired size\n",
    "    transforms.ToTensor(),  # Convert to tensor\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])  # Normalize (adjust mean and std as needed)\n",
    "])\n",
    "\n",
    "test_dataset = datasets.ImageFolder(root=test_dir, transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=25, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "def test_model(model, test_loader, device):\n",
    "    model.eval()\n",
    "    y_true, y_pred = [], []\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            _, predicted = torch.max(output, 1)\n",
    "            y_true.extend(target.cpu().numpy())\n",
    "            y_pred.extend(predicted.cpu().numpy())\n",
    "\n",
    "    # Calculate metrics\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "    recall = recall_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "    class_report = classification_report(y_true, y_pred, zero_division=0)\n",
    "\n",
    "    print(f\"Confusion Matrix:\\n{cm}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    print(f\"Classification Report:\\n{class_report}\")\n",
    "\n",
    "    return cm, precision, recall, f1, class_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[2 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1]\n",
      " [0 0 2 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0]\n",
      " [0 1 0 2 0 0 0 1 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 4 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 1 0 0 0 0 0 0 2 0 0 1]\n",
      " [0 0 0 0 1 0 0 2 0 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 0 0 3 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 4 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 3 0 0 1 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 1 2 0 0 0 0 0 1]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 1]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 1]\n",
      " [0 0 0 0 0 0 0 0 0 2 0 0 0 0 2 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 2]\n",
      " [1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 2 0]\n",
      " [0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 3]]\n",
      "Precision: 0.6087\n",
      "Recall: 0.5833\n",
      "F1 Score: 0.5621\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.50      0.57         4\n",
      "           1       0.50      0.25      0.33         4\n",
      "           2       0.67      0.50      0.57         4\n",
      "           3       1.00      0.50      0.67         4\n",
      "           4       0.80      1.00      0.89         4\n",
      "           5       0.80      1.00      0.89         4\n",
      "           6       0.00      0.00      0.00         4\n",
      "           7       0.50      0.50      0.50         4\n",
      "           8       1.00      0.75      0.86         4\n",
      "           9       0.44      1.00      0.62         4\n",
      "          10       0.43      0.75      0.55         4\n",
      "          11       1.00      0.50      0.67         4\n",
      "          12       0.60      0.75      0.67         4\n",
      "          13       0.75      0.75      0.75         4\n",
      "          14       0.50      0.50      0.50         4\n",
      "          15       0.00      0.00      0.00         4\n",
      "          16       1.00      0.50      0.67         4\n",
      "          17       0.30      0.75      0.43         4\n",
      "\n",
      "    accuracy                           0.58        72\n",
      "   macro avg       0.61      0.58      0.56        72\n",
      "weighted avg       0.61      0.58      0.56        72\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cm, precision, recall, f1, class_report = test_model(model, test_loader, torch.device('cuda' if torch.cuda.is_available() else 'cpu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "1. **Confusion Matrix**: A table that is used to describe the performance of a classification model. It shows the number of correct and incorrect predictions made by the model compared to the actual classifications.\n",
    "\n",
    "2. **Precision**: The ratio of correctly predicted positive observations to the total predicted positives. It answers the question: \"Of all the instances that were predicted as a certain class, how many were actually that class?\"\n",
    "\n",
    "3. **Recall**: The ratio of correctly predicted positive observations to the all observations in the actual class. It answers the question: \"Of all the instances that actually belong to a certain class, how many were correctly predicted?\"\n",
    "\n",
    "4. **F1 Score**: The weighted average of Precision and Recall. It is useful when you need a balance between Precision and Recall.\n",
    "\n",
    "5. **Classification Report**: A detailed report showing the Precision, Recall, and F1 Score for each class. It provides a comprehensive overview of the model's performance across all classes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
