{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tempfile\n",
    "\n",
    "from minio import Minio\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "\n",
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "REMOTE_MLFLOW_STORAGE_URI = os.getenv(\"REMOTE_MLFLOW_STORAGE_URI\")\n",
    "REMOTE_MLFLOW_BUCKET_NAME = os.getenv(\"REMOTE_MLFLOW_BUCKET_NAME\")\n",
    "AWS_ACCESS_KEY_ID = os.getenv(\"AWS_ACCESS_KEY_ID\")\n",
    "AWS_SECRET_ACCESS_KEY = os.getenv(\"AWS_SECRET_ACCESS_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the MinIO client\n",
    "minio_client = Minio(\n",
    "    endpoint=REMOTE_MLFLOW_STORAGE_URI,\n",
    "    access_key=AWS_ACCESS_KEY_ID,\n",
    "    secret_key=AWS_SECRET_ACCESS_KEY,\n",
    "    secure=True\n",
    ")\n",
    "\n",
    "# List all objects in the bucket\n",
    "objects = minio_client.list_objects(REMOTE_MLFLOW_BUCKET_NAME, prefix=\"\", recursive=True)\n",
    "\n",
    "for obj in objects:\n",
    "    print(obj.object_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the bucket name and object path\n",
    "local_file_path = \"latest_model_from_mlflow/\"\n",
    "\n",
    "# List and download all objects in the specified path\n",
    "def download_objects_from_minio(minio_client, bucket_name, s3_path_to_model, local_file_path):\n",
    "    objects = minio_client.list_objects(bucket_name, prefix=s3_path_to_model, recursive=True)\n",
    "    for obj in objects:\n",
    "        local_file = os.path.join(local_file_path, os.path.relpath(obj.object_name, s3_path_to_model))\n",
    "        os.makedirs(os.path.dirname(local_file), exist_ok=True)\n",
    "        minio_client.fget_object(bucket_name, obj.object_name, local_file)\n",
    "\n",
    "download_objects_from_minio(\n",
    "    minio_client, \n",
    "    REMOTE_MLFLOW_BUCKET_NAME, \n",
    "    \"data\", \n",
    "    local_file_path\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_preprocessed_spectrogram(audio_path, sr=22050, n_mels=128, fmax=8000, img_size=(224, 224), start_time=20, segment_duration=20):\n",
    "    try:\n",
    "        # Load the audio file\n",
    "        y, sr = librosa.load(audio_path, sr=sr, offset=start_time, duration=segment_duration)\n",
    "        \n",
    "        # Generate the spectrogram\n",
    "        S = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=n_mels, fmax=fmax)\n",
    "        S_DB = librosa.power_to_db(S, ref=np.max)\n",
    "        \n",
    "        # Plot the spectrogram\n",
    "        plt.figure(figsize=(10, 4))\n",
    "        plt.axis('off')\n",
    "        librosa.display.specshow(S_DB, sr=sr, x_axis=None, y_axis=None, fmax=fmax)\n",
    "        \n",
    "        # Save the plot to a temporary file\n",
    "        with tempfile.NamedTemporaryFile(suffix='.png', delete=False) as tmpfile:\n",
    "            plt.savefig(tmpfile.name, bbox_inches='tight', pad_inches=0)\n",
    "            plt.close()\n",
    "            \n",
    "            # Open the image and resize it\n",
    "            img = Image.open(tmpfile.name).convert('RGB')  # Convert to RGB\n",
    "            img = img.resize(img_size, Image.Resampling.LANCZOS)\n",
    "            os.remove(tmpfile.name)\n",
    "        \n",
    "        # Transform the image to tensor\n",
    "        transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "        ])\n",
    "        img_tensor = transform(img).unsqueeze(0)  # Add batch dimension\n",
    "        \n",
    "        return img_tensor\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {audio_path}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device\n",
    "# model_from_minio = MusicNet(num_classes=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/04 19:10:22 WARNING mlflow.pytorch: Stored model version '2.5.0+cu121' does not match installed PyTorch version '2.6.0.dev20241104+cu124'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MusicNet(\n",
       "  (conv1): Conv2d(3, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv3): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv4): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (batchnorm1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (batchnorm2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (batchnorm3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (batchnorm4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       "  (fc1): Linear(in_features=12544, out_features=18, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the model state dictionary\n",
    "model_from_minio = mlflow.pytorch.load_model(local_file_path, map_location=torch.device('cpu'))\n",
    "model_from_minio.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: reggae\n"
     ]
    }
   ],
   "source": [
    "# Preprocess the audio file and make a prediction\n",
    "audio_path = \"/home/kin/Documents/music_similarity/preprocessing/MegaSet/Clinton Fearon/Clinton Fearon - 2010 - Mi Deh Yah/01-clinton_fearon-life_is_a_journey.mp3\"  # reggae\n",
    "img_tensor = create_preprocessed_spectrogram(audio_path)\n",
    "\n",
    "mapping = {'blues': 0,\n",
    " 'chanson': 1,\n",
    " 'classical': 2,\n",
    " 'country': 3,\n",
    " 'dance': 4,\n",
    " 'dub': 5,\n",
    " 'electro': 6,\n",
    " 'folk': 7,\n",
    " 'funk': 8,\n",
    " 'hard rock': 9,\n",
    " 'hip-hop': 10,\n",
    " 'house': 11,\n",
    " 'jazz': 12,\n",
    " 'metal': 13,\n",
    " 'pop': 14,\n",
    " 'rap': 15,\n",
    " 'reggae': 16,\n",
    " 'rock': 17}\n",
    "\n",
    "# Make a prediction\n",
    "if img_tensor is not None:\n",
    "    img_tensor = img_tensor.to(device)\n",
    "    model_from_minio.eval()\n",
    "    with torch.no_grad():\n",
    "        output = model_from_minio(img_tensor)\n",
    "        _, predicted = torch.max(output, 1)\n",
    "    \n",
    "    # Create a reverse mapping from index to class name\n",
    "    idx_to_class = {v: k for k, v in mapping.items()}\n",
    "\n",
    "    # Get the predicted class name\n",
    "    predicted_class_name = idx_to_class[predicted.item()]\n",
    "\n",
    "    # Print the predicted class\n",
    "    print(f'Predicted class: {predicted_class_name}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
